{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zy0Y6xTLNtM6"
   },
   "source": [
    "# Introductie tot Deep Learning met Keras en TensorFlow\n",
    "## Les 10. Convolutionele neurale netwerken\n",
    "\n",
    "**Thijs van den Berg, Tijmen Muller en Joost Vanstreels (2021)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cro1QI9NtM7"
   },
   "source": [
    "In de eerste twee lessen waarin we dit notebook gebruikt hebben, zijn we aan de slag gegaan met neurale netwerken. In deze les gebruiken we het notebook een laatste keer om aan de slag te gaan met convolutionele neurale netwerken (CNN's of ConvNets), één van de vormen van deep learning. \n",
    "\n",
    "We zullen zien dat neurale netwerken een aantal beperkingen hebben en hoe we die beperkingen kunnen oplossen met ConvNets. Tijdens deze workshop gaan we de basisstappen doorlopen om een simpel ConvNet te maken met behulp van de populaire libraries van Google. We gaan de Keras library gebruiken, deze library gebruikt onder water de TensorFlow library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgLiUhUr4t4d"
   },
   "source": [
    "## Doel notebook\n",
    "\n",
    "Het doel van dit notebook is om een aantal voorbeelden te geven van de werking van convolutionele netwerken neurale netwerken:\n",
    "- Wat zijn de beperkingen van neurale netwerken?\n",
    "- Wat is de toegevoegde waarde van convolutionele netwerken?\n",
    "- Hoe werken deze convolutionele netwerken?\n",
    "\n",
    "## Opzet notebook\n",
    "\n",
    "Dit notebook bevat geen opdrachten maar enkel theoretische uitleg en praktische codevoorbeelden over de volgende onderwerpen:\n",
    "- Convolutie\n",
    "- Filters\n",
    "- Padding\n",
    "- Pooling\n",
    "- De architectuur van een ConvNet\n",
    "- Data augmentation\n",
    "\n",
    "Het notebook bestaat uit drie delen:\n",
    "- I. De beperkingen van neurale netwerken\n",
    "- II. Een eerste ConvNet voor MNIST\n",
    "- III. ConvNet voor MNIST met augmented data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpfctwLyNtM7"
   },
   "source": [
    "# Deel I. De beperkingen van neurale netwerken\n",
    "\n",
    "We hebben in het eerste deel van de workshop zijn we aan de slag gegaan met de 'Hello World' van neurale netwerken: het herkennen van de handgeschreven cijfers van de MNIST dataset. De dataset is redelijk gestructureerd, plaatjes staan bijvoorbeeld altijd in het midden en zijn altijd ongeveer even groot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mo8rdjbBNtM7"
   },
   "source": [
    "<img src=\"https://i.imgur.com/86wacJG.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jc0B9Je6kpVI"
   },
   "source": [
    "## Beperkingen van neurale netwerken\n",
    "\n",
    "De netwerken die we getraind hebben, behaalden scores van zo'n 98% accuracy. Da's zeker niet slecht! Maar wat zou er gebeuren wanneer de plaatjes er net even iets anders uit zien?\n",
    "\n",
    "In onderstaand plaatje zie een '3' en een aantal varianten:\n",
    "\n",
    "<img src=\"https://i.imgur.com/KfyF1v2.png\" />\n",
    "\n",
    "Het is telkens dezelfde 3 maar dan:\n",
    "- Verplaatst;\n",
    "- Verkleurd;\n",
    "- Gedraaid;\n",
    "- Verkleind;\n",
    "- Negatief.\n",
    "\n",
    "In alle gevallen zal ons neuraal netwerk de m`n`ist in gaan omdat deze drieën afwijken van de drieën in de trainset. Je zou dit soort afwijkende drieën kunnen toevoegen aan de trainset maar bij een nieuwe afwijking slaat je netwerk weer eerst de plank mis. \n",
    "\n",
    "Laten we dit eerst aantonen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjDwn6ArNtM7"
   },
   "source": [
    "## Benodigde libraries \n",
    "\n",
    "We hebben een aantal libraries nodig, sommigen kennen jullie al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QfscTgLkNtM8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random  \n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.datasets import mnist     # MNIST dataset is onderdeel van Keras\n",
    "from tensorflow.keras.models import Sequential  # Het type neuraal netwerk dat we gaan gebruiken\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation  # Verschillende type lagen die we gaan gebruiken\n",
    "from tensorflow.keras.optimizers import SGD, Adam, schedules\n",
    "from tensorflow.keras import utils    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA-shizzle\n",
    "# Geheugengebruik GPU beperken\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "print(f\"TensorFlow v{tf.version.VERSION}, {len(tf.config.list_physical_devices('GPU'))} GPUs:\")\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QljqpqwxNtM8"
   },
   "source": [
    "## Stap 1. Data exploration \n",
    "\n",
    "De MNIST dataset is gebundeld in Keras, we kunnen deze eenvoudig downloaden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRVKdbbDNtM8",
    "outputId": "b80c8fd3-1368-4929-cc68-2f777a1f3b61"
   },
   "outputs": [],
   "source": [
    "# Inladen van de dataset, deze is al gesplitst in een train- en testset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"x_train shape\", x_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"x_test shape\", x_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SPa5opaGlFk"
   },
   "source": [
    "## Stap 2. Data preparation \n",
    "\n",
    "We gaan de dataset zodanig aanpassen dat de plaatjes wat minder gestructureerd zijn. We noemen dit *data augmentation*: het vergroten van de dataset met extra plaatjes. De nieuwe plaatjes zijn gebaseerd op de bestaande plaatjes. We gebruiken een aantal manieren om de plaatjes aan te passen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nnDGz2UVBO0Y",
    "outputId": "4ea14e51-38eb-4ee9-ae0d-4731411ce223"
   },
   "outputs": [],
   "source": [
    "X_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "X_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "print(\"Training matrix shape\", X_train.shape)\n",
    "print(\"Testing matrix shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4frk26HOGMHY",
    "outputId": "9eb4444d-fc2a-47a5-e244-b72e584479d2"
   },
   "outputs": [],
   "source": [
    "## Met np_utils wordt de one-hot encoding gedaan\n",
    "nb_classes = 10 # aantal classes\n",
    "\n",
    "Y_train = utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print(f\"Y_train: {Y_train.shape}, Y_test: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDjt7MQMwbNY"
   },
   "source": [
    "### Data augmentation\n",
    "Hieronder wordt code getoond voor een aantal acties zoals het draaien, verplaatsen, rekken en zoomen van plaatjes. Dit soort aanpassingen wordt *data augmentation* genoemd.\n",
    "\n",
    "Eerst moeten we een library importeren en gebruiken we een functie om de resultaten te visualiseren. We zullen eerst een aantal voorbeelden geven van de werking van deze library. De code is afkomstig van https://medium.com/the-data-science-publication/how-to-augment-the-mnist-dataset-using-tensorflow-4fbf113e99a0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Npp-VhYCAfj"
   },
   "outputs": [],
   "source": [
    "# import relevant library\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8xxKzlnePZ_"
   },
   "outputs": [],
   "source": [
    "# Code om voor en na te visualiseren\n",
    "def plot_numbers(x, X, y):\n",
    "\n",
    "  # define number of rows & columns\n",
    "  num_row = 2\n",
    "  num_col = 8\n",
    "  num= num_row*num_col\n",
    "  # plot before\n",
    "  print('BEFORE:\\n')\n",
    "  # plot images\n",
    "  fig1, axes1 = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "  for i in range(num):\n",
    "      ax = axes1[i//num_col, i%num_col]\n",
    "      ax.imshow(x[i], cmap='gray_r')\n",
    "      ax.set_title('Label: {}'.format(y[i]))\n",
    "  #plt.tight_layout()\n",
    "  plt.show()\n",
    "  # plot after\n",
    "  print('AFTER:\\n')\n",
    "  fig2, axes2 = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "  for X, Y in datagen.flow(X,y.reshape(y.shape[0], 1),batch_size=num,shuffle=False):\n",
    "      for i in range(0, num):\n",
    "            ax = axes2[i//num_col, i%num_col]\n",
    "            ax.imshow(X[i].reshape(28,28), cmap='gray_r')\n",
    "            ax.set_title('Label: {}'.format(int(Y[i])))\n",
    "      break\n",
    "  #plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8zR33BjZ0Ye"
   },
   "source": [
    "#### Draaien\n",
    "Hieronder wordt code getoond voor het draaien van plaatjes. De input parameter is een waarde voor maximale draaihoek. De ImageDataGenerator library kiest willekeurig voor de richting waarin gedraaid wordt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "yoAZwZAWo1Wx",
    "outputId": "71719d4b-ef71-4533-b851-782304560a98"
   },
   "outputs": [],
   "source": [
    "# specify the maximum rotation_range angle\n",
    "rotation_range_val = 30\n",
    "\n",
    "# create the class object\n",
    "datagen = ImageDataGenerator(rotation_range=rotation_range_val)\n",
    "# fit the generator\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Hieronder vind je de code voor het visualiseren van de veranderingen\n",
    "plot_numbers(x_train, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BtFE_A_woOw"
   },
   "source": [
    "#### Verplaatsen\n",
    "Hieronder wordt code getoond voor het verplaatsen van plaatjes. De input parameters zijn een waarde voor de mate waarin horizontaal en verticaal verschoven mag worden. De ImageDataGenerator library kiest willekeurig voor de richtingen waarin verplaatst wordt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "lhM3lcfpu2KH",
    "outputId": "1593ebe5-572f-4003-bc91-7142df942342"
   },
   "outputs": [],
   "source": [
    "# specify the width and height shift arguments\n",
    "width_shift_val = 0.25\n",
    "height_shift_val = 1.25\n",
    "\n",
    "# create the class object\n",
    "datagen = ImageDataGenerator(width_shift_range=width_shift_val, height_shift_range=height_shift_val)\n",
    "\n",
    "# fit the generator\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Hieronder vind je de code voor het visualiseren van de veranderingen\n",
    "plot_numbers(x_train, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1yK3rlk5MZF"
   },
   "source": [
    "#### Rekken\n",
    "Hieronder wordt code getoond voor het in- en uitrekken van plaatjes. De input parameter is een waarde voor de mate waarin gerekt kan worden. De ImageDataGenerator library kiest willekeurig voor een waarde voor zowel horizontaal als verticaal rekken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "x021Blaa5Ia0",
    "outputId": "0669972d-d4e8-4574-c30c-3799cee9d1ab"
   },
   "outputs": [],
   "source": [
    "# specify the shear argument\n",
    "shear_range_val=45\n",
    "\n",
    "# create the class object\n",
    "datagen = ImageDataGenerator(shear_range=shear_range_val)\n",
    "\n",
    "# fit the generator\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Hieronder vind je de code voor het visualiseren van de veranderingen\n",
    "plot_numbers(x_train, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jz7AK4S5oQK"
   },
   "source": [
    "#### Zoomen\n",
    "Hieronder wordt code getoond voor het in- en uitzoomen van plaatjes. De input parameter is een bereik voor het in- en uitzoomen. De ImageDataGenerator library kiest willekeurig voor een waarde voor zowel horizontaal als verticaal inzoomen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "kpMmtZTZ5oQQ",
    "outputId": "6e2040ab-3e3a-460e-ed9b-d59dca0a8890"
   },
   "outputs": [],
   "source": [
    "# specify the zoom argument\n",
    "zoom_range_val=[0.5,1.5]\n",
    "\n",
    "# create the class object\n",
    "datagen = ImageDataGenerator(shear_range=shear_range_val)\n",
    "\n",
    "# fit the generator\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Hieronder vind je de code voor het visualiseren van de veranderingen\n",
    "plot_numbers(x_train, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgYCoAycWW-j"
   },
   "source": [
    "### ImageDataGenerator object aanmaken\n",
    "\n",
    "De library van Keras maakt het mogelijk om alle aanpassingen te combineren. Hiervoor maak je een ImageDataGenerator object aan waarin je alle aanpassingen specificeert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lYcBJ72xrl4"
   },
   "outputs": [],
   "source": [
    "# Bron: https://keras.io/api/preprocessing/image/\n",
    "\n",
    "# Bereik / maximale waardes van de aanpassingen specificeren\n",
    "rotation_range_val = 15\n",
    "width_shift_val = 0.15\n",
    "height_shift_val = 0.15\n",
    "shear_range_val = 25\n",
    "zoom_range_val = [0.9,1.1]\n",
    "\n",
    "# Combineren in een ImageDataGenerator object\n",
    "datagen = ImageDataGenerator(rotation_range = rotation_range_val,\n",
    "                             width_shift_range = width_shift_val,\n",
    "                             height_shift_range = height_shift_val,\n",
    "                             zoom_range=zoom_range_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HltOE4KZcyTs"
   },
   "source": [
    "En nu gaan we `X_test` aanpassen: we gaan het ImageDataGenerator object toepassen op deze testset. Dat betekent dat we de plaatjes in deze testset aan gaan laten passen. Voor elk plaatje zullen willekeurige aanpassingen uitgevoerd worden binnen het bereik dat het gespecificeerd is in het ImageDataGenerator object. \n",
    "\n",
    "Het resultaat slaan we op in `X_test_augmented`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFf4YUnsZLBN"
   },
   "outputs": [],
   "source": [
    "# Voordat de plaatjes aangepast kunnen worden, moeten er een aantal berekeningen uitgevoerd worden op het object\n",
    "datagen.fit(X_test)\n",
    "\n",
    "# De resultaten slaan we op in een nieuwe dataset\n",
    "X_test_augmented, Y_test_augmented = next(datagen.flow(X_test, Y_test, batch_size=X_test.shape[0], shuffle=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqv4iPwugP6v"
   },
   "source": [
    "Je ziet hieronder dat de plaatjes gedraaid, verplaatst, vergroot en gerekt worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "7I4m4ogveetZ",
    "outputId": "d9e9cc42-ad7a-4c60-e88d-7c1fb2b20bf7"
   },
   "outputs": [],
   "source": [
    "plot_numbers(x_test, X_test_augmented, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0FVqFYSaqoF"
   },
   "outputs": [],
   "source": [
    "# Nu moeten we de nieuwe datasets nog reshapen voor het neuraal netwerk\n",
    "\n",
    "X_train = x_train.reshape(60_000, 784)  # Reshape de 60.000 plaatjes van 28 x 28 matrices naar 60.000 784-lengte vectoren.\n",
    "X_test = x_test.reshape(10_000, 784)\n",
    "X_test_augmented = X_test_augmented.reshape(10_000, 784)\n",
    "\n",
    "X_train = X_train.astype('float32')         # change integers to 32-bit floating point numbers\n",
    "X_test = X_test.astype('float32')\n",
    "X_test_augmented = X_test_augmented.astype('float32')\n",
    "\n",
    "X_train /= 255  \n",
    "X_test /= 255\n",
    "X_test_augmented /= 255         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PfB_RdJxtW4"
   },
   "source": [
    "## 3. Modelling\n",
    "\n",
    "We gaan eerst een neuraal netwerk opbouwen. Hier gebruiken we het *oude* neuraal netwerk van les 9 voor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vPdhWkOnYac",
    "outputId": "1ecb5851-89ec-4036-d618-bae632056282"
   },
   "outputs": [],
   "source": [
    "model_old = Sequential()\n",
    "model_old.add(Dense(512, input_shape=(784,))) #(784,)\n",
    "model_old.add(Activation('sigmoid'))\n",
    "model_old.add(Dropout(0.4))\n",
    "\n",
    "model_old.add(Dense(512))\n",
    "model_old.add(Activation('sigmoid'))\n",
    "\n",
    "model_old.add(Dense(10))\n",
    "model_old.add(Activation('softmax'))\n",
    "\n",
    "lr_schedule = schedules.ExponentialDecay(initial_learning_rate=0.01,\n",
    "                                         decay_steps=2_000,\n",
    "                                         decay_rate=0.9)\n",
    "\n",
    "opt_adam = Adam(learning_rate=lr_schedule)\n",
    "model_old.compile(loss=\"categorical_crossentropy\", optimizer=opt_adam, metrics=[\"accuracy\"])\n",
    "\n",
    "model_old.fit(X_train, Y_train,\n",
    "               batch_size=128,\n",
    "               epochs=5,\n",
    "               verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JT4Cx2u7NtNH"
   },
   "source": [
    "## Stap 4. Evalueren\n",
    "\n",
    "Laten we eerst nog even kijken hoe goed de score is voor de originele testdata en daarna naar de augmented testdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gMxZZx-oJUXS",
    "outputId": "5c459259-c718-483f-cc7c-45b4b2175ab0"
   },
   "outputs": [],
   "source": [
    "# Score X_test\n",
    "score = model_old.evaluate(X_test, Y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LhBBRZlpZkQr",
    "outputId": "adf4b303-3654-472e-c491-310529373cb6"
   },
   "outputs": [],
   "source": [
    "# score X_test_augmented\n",
    "score = model_old.evaluate(X_test_augmented, Y_test_augmented)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fKh_2zyNtNJ"
   },
   "source": [
    "## Conclusie\n",
    "\n",
    "De vorige keer hebben we gezien dat het neuraal netwerk tot ruim 97% accuracy kon komen, maar met deze augmented testset valt het tegen... Als de plaatjes in de praktijk een klein beetje afwijken, daalt de score tot onder de 50%.\n",
    "\n",
    "We gaan nu kijken hoe dat met ConvNets werkt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xk-luXROUSZ7"
   },
   "source": [
    "# Deel II. Deep learning met convolutionele neurale netwerken\n",
    "\n",
    "## Kijken zoals mensen kijken\n",
    "Wanneer wij een plaatje zien, gaan wij niet naar alle pixels kijken en daarmee bepalen of een plaatje een 3 is of iets anders. Wij kijken naar bepaalde vormen of structuren, bijvoorbeeld de drie pootjes die een drie heeft of de twee rondjes die een acht vormen. We kijken naar scheidingen tussen objecten op een foto of zaken die op de voorgrond of achtergrond staan. Op die manier maken wij onze voorspellingen. En dat is precies wat convolutionele neurale netwerken doen.\n",
    "\n",
    "## Patronen, patronen van patronen en patronen van patronen van patronen\n",
    "Dit is waarschijnlijk de meest onduidelijke koptekst ooit... maar hopelijk verklaart dit plaatje de kop: \n",
    "\n",
    "<img src=\"https://i.imgur.com/wdqFecH.png\" />\n",
    "\n",
    "Je ziet in de onderste laag de patronen die gevonden worden in een plaatje. De tweede laag laat zien dat door combinaties van patronen te maken, je nieuwe patronen vindt (= patronen van patronen). Daarboven zie je dat die patronen van patronen gecombineerd zijn tot patronen van patronen van patronen!\n",
    "\n",
    "Die bovenste patronen van patronen van patronen komen in de buurt van de objecten die we zoeken. En dat is precies wat we willen bereiken met ConvNets!\n",
    "\n",
    "Het idee is dat we niet alle pixels van een plaatje afzonderlijk gaan bekijken maar dat we naar patronen gaan zoeken om op die manier objecten te herkennen. Hoe dat werkt in een ConvNet leggen we hieronder uit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8F-KlRlNtNK"
   },
   "source": [
    "## De bouwstenen van een ConvNet\n",
    "We gaan kijken naar de belangrijkste bouwstenen van een Convnet:\n",
    "1. Convolutionele lagen\n",
    "2. ReLU's\n",
    "3. Pooling\n",
    "4. Fully connected layer\n",
    "\n",
    "### 1. Convolutionele lagen\n",
    "\n",
    "Convolutionele neurale netwerken voegen nog meer lagen toe aan een netwerk, daar komt de naam *deep learning* vandaan: het netwerk wordt steeds dieper. Maar de convolutionele lagen werken wel iets anders: het zijn lagen die iets speciaal doen zoals randen detecteren of bepaalde clusters van pixels (bijvoorbeeld een *pootje* of een *rondje*). Hier komt unsupervised learning weer om de hoek kijken want de computer gaat zelf bepalen welke clusters vaker terug komen en daarmee interessant zijn.\n",
    "\n",
    "#### Extra features vinden \n",
    "\n",
    "Het doel van convolutie is om extra features te vinden in een plaatje. Tot nu toe beschouwden we alle pixels van een plaatje als de features. Maar met convolutie gaan we op zoek naar nieuwe kenmerken van een plaatje, zoals zo'n *pootje* of *rondje*. \n",
    "\n",
    "#### Local perceptive field\n",
    "\n",
    "Een convolutional layer maakt gebruik van filters. Zo’n filter bekijkt een klein deel van een plaatje, bijvoorbeeld 5 x 5 pixels. Dat filter schuif je over het hele plaatje heen, van links naar rechts en van boven naar beneden. Het idee is dat je met zo’n filter op zoek gaat naar bepaalde patronen van een plaatje. Nielsen gebruikt de term local perceptive field om aan te geven dat je niet het hele plaatje beschouwd, maar kleine delen van het plaatje.\n",
    "\n",
    "<img src = 'https://i.imgur.com/gEm0DqN.gif' >\n",
    "\n",
    "In bovenstaande animatie zie je dat er in dit plaatje van 5 x 5 pixels gekeken wordt naar alle 3 x 3 vlakken in dat plaatje. Met behulp van wiskundige berekeningen wordt er *iets* gezegd over elk vlak. We noemen dat 3 x 3 vlak een *kernel*. De resultaten van deze berekeningen kun je weer opslaan, in dit geval levert dat 9 nieuwe features op naast de originele 25 features (= de 5 x 5 pixels).\n",
    "\n",
    "### Convolutie op convolutie\n",
    "\n",
    "Het mooie van convolutionele lagen, is dat je ze op elkaar kunt stapelen en daarmee de verschillende filters kunt combineren. \n",
    "\n",
    "### 2. Rectified Linear Unit (ReLU)\n",
    "\n",
    "De ReLU is een activatiefunctie net zoals de sigmoid en tanh. ReLU’s zijn erg populair omdat de simpele afgeleide zorgt voor een snellere convergentie bij gradient descent. Daarnaast is het makkelijker om de afgeleide van de ReLU te berekenen en daarom is de ReLU computationeel goedkoper. \n",
    "\n",
    "Een ReLU vervangt in de basis alle negatieve waardes met een 0. Je kunt dit ook zien als een manier om een plaatje te verkleinen: alle output kleiner dan 0 is niet relevant en vervang je met 0. \n",
    "<img src = 'https://miro.medium.com/max/357/1*oePAhrm74RNnNEolprmTaQ.png' >\n",
    "\n",
    "Elke convolutionele laag wordt opgevolgd door een ReLU laag.\n",
    "\n",
    "### 3. Pooling\n",
    "\n",
    "Het idee van een pooling layer is om een plaatje te verkleinen. Met behulp van een MAX pooling filter je de laagste waardes die je gekregen hebt na een convolutional layer om alleen de hoogste waarde over te houden. Je gaat er vanuit dat de hoogste waardes het belangrijkste zijn en dat de andere waardes eigenlijk niet relevant zijn.\n",
    "\n",
    "<img src = 'https://i.imgur.com/AGMVPbL.png' >\n",
    "\n",
    "Na een of meerdere convolutionele en ReLU lagen, voeg je een pool laag toe. \n",
    "\n",
    "De term *deep* uit 'Deep learning' komt van het feit dat je dit vaker kunt doen (dus meerdere conv layers met een pool en dat dan vaker herhalen) waardoor er een heel diep netwerk ontstaat.\n",
    "\n",
    "### 4. Fully connected layer\n",
    "Wat je in de hierboven genoemde lagen eigenlijk doet is patronen van objecten in plaatjes detecteren. En patronen van patronen. En patronen van patronen van patronen. Enzovoorts. Het resultaat van al die lagen is een overzicht van gevonden patronen. En die patronen zijn de input voor het neuraal netwerk dat op basis van deze informatie gaat classificeren. \n",
    "\n",
    "Het laatste deel van een ConvNet is een *fully connected layer* ofwel een *fully connected neural network*. Deze krijgt dus niet het plaatje als input, maar de gevonden patronen. \n",
    "\n",
    "**Merk op**: de output van de allerlaatste laag is weer in de vorm van een of meerdere matrices. Je moet (net als bij een *gewoon* neuraal netwerk) de input vertalen naar een vector.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xfz0njjcNtNL"
   },
   "source": [
    "## Stap 1. Data exploration\n",
    "\n",
    "We gaan een eerste ConvNet bouwen voor de *originele* MNIST data, dus zonder de data aan te passen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5YvLC4vgNtNL"
   },
   "outputs": [],
   "source": [
    "# Aantal extra libraries importeren\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8-Me0udNtNL"
   },
   "outputs": [],
   "source": [
    "# MNIST opnieuw importeren\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZbwCD1l4t4z"
   },
   "source": [
    "## Stap 2. Data preparation\n",
    "\n",
    "Voor het neurale netwerk hebben we de plaatjes omgevormd van een 28 x 28 matrix naar een vector met lengte 784. Dat gaan we straks ook doen, maar eerst willen we de plaatjes intact houden omdat we de filters over de plaatjes heen willen laten gaan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8B-ea0gNtNL",
    "outputId": "da9a3fce-9e78-4b94-82b4-c178e6b0fd18"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')         \n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255                              \n",
    "X_test /= 255\n",
    "\n",
    "print(\"Training matrix shape\", X_train.shape)\n",
    "print(\"Testing matrix shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2HsSOrF8NtNL",
    "outputId": "bbcb99f0-844c-4320-a0f7-d392cffde37e"
   },
   "outputs": [],
   "source": [
    "# One-hot formatten\n",
    "\n",
    "nb_classes = 10 # number of unique digits\n",
    "\n",
    "Y_train = utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print(f\"Y_train: {Y_train.shape}, Y_test: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQk4qq4YWZ0U"
   },
   "source": [
    "## Stap 3. Modelling\n",
    "Hieronder geven we een voorbeeld van een ConvNet voor de standaard MNIST dataset, dus zonder data augmentation.\n",
    "\n",
    "### Model opbouwen\n",
    "\n",
    "Het model bestaat uit een aantal lagen. \n",
    "\n",
    "**1. Conv layer**\n",
    "\n",
    "De eerste laag bestaat uit 32 3x3 filters met een ReLU. De input moet bij de eerste laag expliciet worden gegeven, de dimensies van de input zijn 28x28 pixels en er is maar één kleurwaarde dus vandaar dat de input 28x28x1 is.\n",
    "\n",
    "De default waardes van stride (dat is 1) en padding (geen padding) worden gebruikt. Dat betekent dat de output (de zogenaamde *activation maps*) een dimensie van 26x26 hebben. Omdat er 32 filters zijn, is de totale dimensie 26x26x32. \n",
    "\n",
    "**Merk op:** de conv layers maken gebruik van *batch normalization*, hiermee normaliseer je de gewichten van een laag. Dit is een veelgebruikte manier om sneller en beter te kunnen fitten.\n",
    "\n",
    "**2. Conv layer**\n",
    "\n",
    "De tweede laag bestaat ook weer uit 32 filters van 3x3. Hierna volgt (uiteraard) ook weer een ReLU maar nu ook een max pool van 2x2.\n",
    "\n",
    "De activation maps zijn nu 24x24x32 en na de max pool nog maar 12x12x32.\n",
    "\n",
    "**3. en 4. Conv layers**\n",
    "\n",
    "De derde en vierde laag gebruiken 64 filters waardoor we tot 8x8x64 activation maps komen die in de laatste laag door de max pool tot 4x4x64 verkleind wordt.\n",
    "\n",
    "Laag 4 bevat ook nog de `Flatten` functie om voor de fully connected layer een vector te maken van deze drie-dimensionale matrix.\n",
    "\n",
    "**5. en 6. Fully connected layer**\n",
    "\n",
    "Het neuraal netwerk krijgt als input 1.024 inputs vanuit laag 4. Dat hoef je allemaal niet zelf te specificeren, dat regelt Keras voor je. Je moet natuurlijk wel aangeven uit hoeveel lagen de hidden layer bestaat en de output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EVhMdErjNtNM"
   },
   "outputs": [],
   "source": [
    "model = Sequential()                                 # Linear stacking of layers\n",
    "\n",
    "# Convolution Layer 1\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(28,28,1))) # 32 different 3x3 kernels -- so 32 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "convLayer01 = Activation('relu')                     # activation\n",
    "model.add(convLayer01)\n",
    "\n",
    "# Convolution Layer 2\n",
    "model.add(Conv2D(32, (3, 3)))                        # 32 different 3x3 kernels -- so 32 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "model.add(Activation('relu'))                        # activation\n",
    "convLayer02 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
    "model.add(convLayer02)\n",
    "\n",
    "# Convolution Layer 3\n",
    "model.add(Conv2D(64,(3, 3)))                         # 64 different 3x3 kernels -- so 64 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "convLayer03 = Activation('relu')                     # activation\n",
    "model.add(convLayer03)\n",
    "\n",
    "# Convolution Layer 4\n",
    "model.add(Conv2D(64, (3, 3)))                        # 64 different 3x3 kernels -- so 64 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "model.add(Activation('relu'))                        # activation\n",
    "convLayer04 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
    "model.add(convLayer04)\n",
    "model.add(Flatten())                                 # Flatten final 4x4x64 output matrix into a 1024-length vector\n",
    "\n",
    "# Fully Connected Layer 5\n",
    "model.add(Dense(512))                                # 512 FCN nodes\n",
    "model.add(BatchNormalization())                      # normalization\n",
    "model.add(Activation('relu'))                        # activation\n",
    "\n",
    "# Fully Connected Layer 6                       \n",
    "model.add(Dropout(0.2))                              # 20% dropout of randomly selected nodes\n",
    "model.add(Dense(10))                                 # final 10 FCN nodes\n",
    "model.add(Activation('softmax'))                     # softmax activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5jjXwJ0aaAg"
   },
   "source": [
    "Hieronder zie je het resultaat. Kijk voor even naar de tweede kolom waar de dimensies van de output van elke laag getoond worden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOYGf8x2NtNM",
    "outputId": "a941c1f0-3111-4664-d9a6-6e64203763dc"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQHNt1lPakgW"
   },
   "source": [
    "### Compilen\n",
    "Ook hier moeten we het model gaan compilen met een loss function en optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ufapMx5NtNM"
   },
   "outputs": [],
   "source": [
    "# We gebruiken dezelfde loss function en optimizer als bij het neuraal netwerk\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfkLKdLHeihD"
   },
   "source": [
    "### Fitten\n",
    "\n",
    "Hierna kunnen we het model gaan fitten. De fit functie kent een aantal belangrijke parameters:\n",
    "- batch_size: de grootte van de mini-batch\n",
    "- steps_per_epoch: in principe is dit de grootte van X_train / batch_size en hoef je dat niet te specificeren, maar je kunt ervoor kiezen om slechts een deel van de dataset te gebruiken voor een epoch\n",
    "- validation_split: dit is een hele belangrijke! In de praktijk zul je vaak werken met een train-, test- én devset. De devset gebruik je als een soort tussentijdse testset om tijdens het trainen in de gaten te houden wat de resultaten zijn voor deze testset. Je kunt hiermee in de gaten houden of de scores voor de devset blijven verbeteren en niet minder worden: dat is een indicatie van overfitten. De testset blijft onafhankelijk en gebruik je na afloop van het trainen. Met deze parameter kun je X_train splitsen in een trainset en devset (ter grootte van 0.2 van de originele X_train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTGMQ0FgOQ4t",
    "outputId": "61b965c2-d66d-4527-b722-2670306d46f8"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, batch_size = 128, epochs=5, verbose=1, validation_split = 0.2, validation_steps=12000//128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8Q5fMK_fwrQ"
   },
   "source": [
    "## Stap 4. Evalueren\n",
    "\n",
    "Ook hier kunnen we kijken hoe goed de resultaten zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kdb-DcIuNtNN",
    "outputId": "f6775b0b-cbbe-48ee-b496-f2c9da15275f"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOeGkkw3gEo1"
   },
   "source": [
    "Met een *normaal* neuraal netwerk kwamen we tot ongeveer 97.5% accuracy, met dit ConvNet komen we al tot 99%! Op naar de 100%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-3XOc1Bh-CQ"
   },
   "source": [
    "Maar we willen natuurlijk ook even kijken hoe goed dit ConvNet het doet op de augmented testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbSQ6EkAcNVn"
   },
   "outputs": [],
   "source": [
    "# Bron: https://keras.io/api/preprocessing/image/\n",
    "\n",
    "# Bereik / maximale waardes van de aanpassingen specificeren\n",
    "rotation_range_val = 15\n",
    "width_shift_val = 0.15\n",
    "height_shift_val = 0.15\n",
    "shear_range_val = 25\n",
    "zoom_range_val = [0.9,1.1]\n",
    "\n",
    "# Combineren in een ImageDataGenerator object\n",
    "datagen = ImageDataGenerator(rotation_range = rotation_range_val,\n",
    "                             width_shift_range = width_shift_val,\n",
    "                             height_shift_range = height_shift_val,\n",
    "                             zoom_range=zoom_range_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FRJdFP3lcNVy"
   },
   "outputs": [],
   "source": [
    "# Nu gaan we de datasets aanpassen\n",
    "\n",
    "# Voordat de plaatjes aangepast kunnen worden, moeten er een aantal berekeningen uitgevoerd worden op het object\n",
    "datagen.fit(X_test)\n",
    "\n",
    "# De resultaten slaan we op in een nieuwe dataset\n",
    "X_test_augmented, Y_test_augmented = next(datagen.flow(X_test, Y_test, batch_size=10_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8LZzADfcZKc",
    "outputId": "c7bc8753-578b-44cd-965d-7aa466072c2a"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test_augmented, Y_test_augmented)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZD666CXFCWVJ"
   },
   "source": [
    "Je ziet dat de accuracy hier ongeveer 75% is. Het ConvNet is nog niet zo robuust als we zouden hopen, maar ~75% is nog steeds een aardige score, zeker in vergelijking met de 50% van het neuraal netwerk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ugdPPfrNtNO"
   },
   "source": [
    "# Deel III. Trainen met augmented data\n",
    "\n",
    "Augmented data wordt in de praktijk om meerdere redenen gebruikt. \n",
    "\n",
    "- Dataset vergroten. Je kunt hiermee makkelijk je dataset uitbreiden. De aangepaste plaatjes zijn eigenlijk nieuwe plaatjes. Je kunt zo dus makkelijk je dataset vergroten.\n",
    "- Overfitten voorkomen. Door aangepaste varianten van plaatjes aan te bieden aan je netwerk, verklein je de kans dat het netwerk zich aanpast aan de traindata.\n",
    "- Robuustheid vergroten. Door het netwerk te trainen op allerlei varianten, zal het netwerk daar in de praktijk ook rekening mee houden. \n",
    "\n",
    "Dat klinkt misschien allemaal wat vaag, maar dat gaan we nu aantonen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdQdZqNqD11K"
   },
   "source": [
    "## Opzet experiment\n",
    "\n",
    "We gaan eerst een ConvNet trainen op augmented data om daarna te kijken of de scores voor testdata veranderd zijn.\n",
    "\n",
    "## Stap 2. Data preparation\n",
    "De data hoeven we niet meer te bekijken, we gaan meteen door naar stap 2.: alle data weer prepareren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMwGEIpScZRo"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pz3eYQX5cZUm"
   },
   "outputs": [],
   "source": [
    "nb_classes = 10 # number of unique digits\n",
    "\n",
    "Y_train = utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Z8-jwk1FArN"
   },
   "outputs": [],
   "source": [
    "# Bereik / maximale waardes van de aanpassingen specificeren\n",
    "rotation_range_val = 15\n",
    "width_shift_val = 0.15\n",
    "height_shift_val = 0.15\n",
    "shear_range_val = 25\n",
    "zoom_range_val = [0.9,1.1]\n",
    "\n",
    "# Combineren in een ImageDataGenerator object\n",
    "datagen = ImageDataGenerator(rotation_range = rotation_range_val,\n",
    "                             width_shift_range = width_shift_val,\n",
    "                             height_shift_range = height_shift_val,\n",
    "                             zoom_range=zoom_range_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RlXDYhEFJGL1"
   },
   "source": [
    "**Nieuw!** X_train gaan we niet op een nieuwe manier augmenten. \n",
    "Dit train_generator object maakt gebruik van de flow functie van de ImageDataGenerator. Deze flow functie haalt 128 random plaatjes uit X_train en voert daar random aanpassingen op uit. Deze train_generator geven was als input aan de fit functie van het ConvNet. Dit zorgt ervoor dat elke mini-batch uniek is. Dit zorgt voor een onbeperkte hoeveelheid data en verkleint de kans op overfitten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJO6no4NFFi2"
   },
   "outputs": [],
   "source": [
    "datagen.fit(X_train)\n",
    "train_generator = datagen.flow(X_train, Y_train, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pvsw7SomFMAu"
   },
   "outputs": [],
   "source": [
    "# X_test augmenten we wel op de oude manier\n",
    "datagen.fit(X_test)\n",
    "\n",
    "# De resultaten slaan we op in een nieuwe dataset\n",
    "X_test_augmented, Y_test_augmented = next(datagen.flow(X_test, Y_test, batch_size=10_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZ4qgNJQHBlY"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')         \n",
    "X_test = X_test.astype('float32')\n",
    "X_test_augmented.astype('float32')\n",
    "\n",
    "X_train /= 255                              \n",
    "X_test /= 255\n",
    "X_test_augmented /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wrb8OkcrFSCd"
   },
   "source": [
    "## Stap 3. Modelling\n",
    "\n",
    "We gaan het ConvNet trainen op de augmented data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7Tg6G62XLMK"
   },
   "outputs": [],
   "source": [
    "model = Sequential()                                 # Linear stacking of layers\n",
    "\n",
    "# Convolution Layer 1\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(28,28,1))) # 32 different 3x3 kernels -- so 32 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "convLayer01 = Activation('relu')                     # activation\n",
    "model.add(convLayer01)\n",
    "\n",
    "# Convolution Layer 2\n",
    "model.add(Conv2D(32, (3, 3)))                        # 32 different 3x3 kernels -- so 32 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "model.add(Activation('relu'))                        # activation\n",
    "convLayer02 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
    "model.add(convLayer02)\n",
    "\n",
    "# Convolution Layer 3\n",
    "model.add(Conv2D(64,(3, 3)))                         # 64 different 3x3 kernels -- so 64 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "convLayer03 = Activation('relu')                     # activation\n",
    "model.add(convLayer03)\n",
    "\n",
    "# Convolution Layer 4\n",
    "model.add(Conv2D(64, (3, 3)))                        # 64 different 3x3 kernels -- so 64 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "model.add(Activation('relu'))                        # activation\n",
    "convLayer04 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
    "model.add(convLayer04)\n",
    "model.add(Flatten())                                 # Flatten final 4x4x64 output matrix into a 1024-length vector\n",
    "\n",
    "# Fully Connected Layer 5\n",
    "model.add(Dense(512))                                # 512 FCN nodes\n",
    "model.add(BatchNormalization())                      # normalization\n",
    "model.add(Activation('relu'))                        # activation\n",
    "\n",
    "# Fully Connected Layer 6                       \n",
    "model.add(Dropout(0.2))                              # 20% dropout of randomly selected nodes\n",
    "model.add(Dense(10))                                 # final 10 FCN nodes\n",
    "model.add(Activation('softmax'))                     # softmax activation\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNQR9_d_IdNP"
   },
   "outputs": [],
   "source": [
    "train_generator = datagen.flow(X_train, Y_train, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0dBN39FFiqu",
    "outputId": "e3d786d1-5a88-42fa-98c0-b0f01f2ce83e"
   },
   "outputs": [],
   "source": [
    "model.fit(train_generator, steps_per_epoch=60000//128, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWJJLA07qMvC"
   },
   "source": [
    "## Stap 4. Evalueren\n",
    "\n",
    "Ook hier kunnen we kijken hoe goed de resultaten zijn. De vorige keer zagen we goeie scores voor de testset maar niet voor de augmented testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D3FhiHXWFiyF",
    "outputId": "ff8529d0-16f4-456b-c06d-910365c1413a"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test_augmented, Y_test_augmented)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n4X4DePJFiuM",
    "outputId": "39a3c5f4-a415-462e-891e-153c6b6b2fe2"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kH3hslNJqbXb"
   },
   "source": [
    "### Conclusies\n",
    "\n",
    "We zien nu dat de score voor de augmented testset ook harstikke goed is. Ook voor de normale testset is de score heel goed, zelfs hoger dan bij het trainen op de normale traindata! Het model is dus een stuk robuuster én beter geworden. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "Les 10. Voorbeeld convolutionele neurale netwerken met MNIST dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
